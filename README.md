# GitHub Trending Tracker

> **Disclaimer**: This codebase is entirely generated by GLM 4.7 and MiniMax M2.1 AI models.

A smart agent that tracks GitHub trending repositories, filters new repositories, summarizes them using LLM, and sends email reports.

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

## Features

- **Web Scraping**: Scrapes GitHub trending page directly without API limitations
- **Retry Mechanism**: Built-in retry logic with exponential backoff for robust fetching
- **Concurrent API Enrichment**: Uses thread pool to fetch repository details concurrently
- **Smart Filtering**: Identifies genuinely new repositories (not seen in the last X days)
- **LLM Summarization**: Uses AI (OpenAI/Anthropic-compatible APIs) to generate concise summaries
- **Email Reports**: Sends beautiful HTML email reports with summaries
- **Flexible LLM Support**: Works with OpenAI, Anthropic, and compatible APIs (e.g., GLM-4)
- **Scheduler**: Automated daily execution with configurable timezone
- **Structured Logging**: Rotating log files with console output

## Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/gh-trending-tracker.git
cd gh-trending-tracker

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

## Configuration

### 1. Copy Configuration File

Copy the example configuration and modify it:

```bash
cp config.yaml.example config.yaml
```

Then edit `config.yaml` with your settings. Key configuration sections:

- **github**: GitHub API token (optional, for enriching repository data with additional details)
- **trending**: Set period (`daily`/`weekly`/`monthly`), language filter, and limit
- **filter**: Configure `days_threshold` to determine what counts as a "new" repository
- **llm**: Choose provider (`openai`/`anthropic`), model name, and optional custom `base_url`
- **email**: SMTP settings including host, port, credentials, and SSL/TLS configuration
- **scheduler**: Enable/disable and set daily run time with timezone

See `config.yaml` in the project for a complete example with all available options.

### 2. Environment Variables

Copy the example environment file and add your credentials:

```bash
cp .env.example .env
```

Then edit `.env` with your actual values:

```bash
GITHUB_TOKEN=your_github_token          # Optional, for API enrichment
LLM_API_KEY=your_llm_api_key           # Required for LLM summarization
SMTP_USERNAME=your-email@example.com   # Your SMTP username
SMTP_PASSWORD=your-app-password        # Your SMTP password
```

**Note**: For Gmail, use an [App Password](https://support.google.com/accounts/answer/185833) instead of your regular password.

## Usage

### Run Once

Execute the pipeline once and exit:

```bash
python -m src.scheduler --run-once
```

### Run as Scheduler

Run continuously with scheduled execution:

```bash
python -m src.scheduler
```

## Systemd Service (Linux)

To run the application as a system service that starts automatically on boot:

### 1. Install the Service

```bash
# Copy the service file
sudo cp gh-trending-tracker.service.example /etc/systemd/system/gh-trending-tracker.service

# Edit the service file to match your setup
sudo nano /etc/systemd/system/gh-trending-tracker.service
```

### 2. Configure the Service

Update these fields in the service file:

- `User=your-username` - User to run the service as
- `Group=your-group` - Group to run the service as
- `WorkingDirectory=/path/to/gh-trending-tracker` - Project directory
- `Environment="PATH=..."` - Update with your virtual environment path

**Optional: Proxy Configuration**

If you need to use a proxy, uncomment and modify the proxy settings:

```ini
#Environment="HTTP_PROXY=http://proxy.example.com:8080"
#Environment="HTTPS_PROXY=http://proxy.example.com:8080"
#Environment="NO_PROXY=localhost,127.0.0.1"
```

Common proxy formats:
- `http://proxy.example.com:8080` - HTTP proxy
- `http://user:pass@proxy.example.com:8080` - With authentication
- `socks5://proxy.example.com:1080` - SOCKS5 proxy

### 3. Enable and Start the Service

```bash
# Reload systemd configuration
sudo systemctl daemon-reload

# Enable the service to start on boot
sudo systemctl enable gh-trending-tracker.service

# Start the service
sudo systemctl start gh-trending-tracker.service

# Check service status
sudo systemctl status gh-trending-tracker.service
```

### 4. Service Management Commands

```bash
# View logs
sudo journalctl -u gh-trending-tracker.service -f

# Stop the service
sudo systemctl stop gh-trending-tracker.service

# Restart the service
sudo systemctl restart gh-trending-tracker.service

# Disable auto-start on boot
sudo systemctl disable gh-trending-tracker.service
```

### Send Latest Report

Generate and email a report from recent database entries:

```bash
python -m src.scheduler --send-email
```

### Command Line Arguments

- `--run-once`: Run the task once and exit
- `--send-email`: Send the latest report via email
- `--email-file`: Path to a specific HTML report file to send (use with `--send-email`)
- `--config`: Path to configuration file (default: `config.yaml`)

## Project Structure

```
gh-trending-tracker/
├── src/
│   ├── __init__.py
│   ├── config.py           # Configuration management with Pydantic
│   ├── emailer.py          # Email sending with HTML templates
│   ├── fetcher.py          # GitHub API client for enrichment
│   ├── filter.py           # Repository filtering and persistence (SQLite)
│   ├── llm.py             # LLM integration (OpenAI/Anthropic-compatible)
│   ├── logger_config.py    # Centralized logging configuration
│   ├── main.py            # Module exports
│   ├── models.py          # Pydantic data models
│   ├── scheduler.py       # Main application and scheduler
│   └── trending_scraper.py # Web scraper for GitHub trending page
├── tests/
│   ├── test_core.py       # Core functionality tests
│   └── test_trending_scraper.py  # Scraper tests
├── data/                  # SQLite database storage
│   └── .gitkeep
├── logs/                  # Log files
│   └── .gitkeep
├── venv/                  # Python virtual environment
├── config.yaml            # Configuration file
├── requirements.txt       # Python dependencies
├── README.md             # This file
└── CLAUDE.md             # Project instructions for Claude Code
```

## How It Works

1. **Scraping**: The scraper fetches GitHub trending page and extracts repository information
   - Basic info: name, description, language, stars, forks
   - Today's star count from trending page

2. **Enrichment** (optional): If GitHub token is provided, use API to get additional details
   - Created/updated/pushed dates
   - Open issues count
   - Owner avatar URL
   - Uses concurrent requests for better performance

3. **Filtering**: Compare with database to identify new repositories
   - Repositories not seen in the last X days are considered "new"
   - Persists all seen repositories to SQLite database

4. **Summarization**: Use LLM to generate concise summaries for new repositories
   - Supports OpenAI, Anthropic, and compatible APIs
   - Customizable prompt template in config.yaml

5. **Email Report**: Send HTML email report with repository summaries
   - Simplified HTML to avoid spam filters
   - Includes repository cards with key information

## Logs

Logs are stored in the `logs/` directory with rotation:
- File format: `gh_trending_YYYYMMDD.log`
- Max size: 10MB per file
- Backup count: 5 files
- Console output also enabled

## Troubleshooting

### Email not sending
- Check SMTP credentials and settings
- For Gmail, use App Password instead of regular password
- Check if port 465 (SSL) or 587 (TLS) is correct for your SMTP provider
- Verify firewall settings allow outbound SMTP connections

### Scraping fails
- Check internet connection
- GitHub might be blocking requests (rate limiting or IP blocking)
- Check logs for error details
- Consider adding delays or using a GitHub token for API fallback

### LLM API errors
- Verify API key is correct
- Check if base_url is accessible (for custom endpoints)
- Ensure model name is correct for your provider
- Check API quota and rate limits

## License

MIT
