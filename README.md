# GitHub Trending Tracker

> **Disclaimer**: This codebase is entirely generated by GLM 4.7 and MiniMax M2.1 AI models.

A smart agent that tracks GitHub trending repositories, filters new repositories, summarizes them using LLM, and sends email reports.

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

## Features

- **Web Scraping**: Scrapes GitHub trending page directly without API limitations
- **Retry Mechanism**: Built-in retry logic with exponential backoff for robust fetching
- **Concurrent API Enrichment**: Uses thread pool to fetch repository details concurrently
- **Smart Filtering**: Identifies genuinely new repositories (not seen in the last X days)
- **LLM Summarization**: Uses AI (OpenAI/Anthropic-compatible APIs) to generate concise summaries
- **Email Reports**: Sends beautiful HTML email reports with summaries
- **Flexible LLM Support**: Works with OpenAI, Anthropic, and compatible APIs (e.g., GLM-4)
- **Scheduler**: Automated daily execution with configurable timezone
- **Structured Logging**: Rotating log files with console output

## Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/gh-trending-tracker.git
cd gh-trending-tracker

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

## Configuration

### 1. Copy Configuration File

Copy the example configuration and modify it:

```bash
cp config.yaml.example config.yaml
```

Then edit `config.yaml` with your settings. Key configuration sections:

- **github**: GitHub API token (optional, for enriching repository data with additional details)
- **trending**: Set period (`daily`/`weekly`/`monthly`), language filter, and limit
- **filter**: Configure `days_threshold` to determine what counts as a "new" repository
- **llm**: Choose provider (`openai`/`anthropic`), model name, and optional custom `base_url`
- **email**: SMTP settings including host, port, credentials, and SSL/TLS configuration
- **scheduler**: Enable/disable and set daily run time with timezone

See `config.yaml` in the project for a complete example with all available options.

### 2. Environment Variables

Copy the example environment file and add your credentials:

```bash
cp .env.example .env
```

Then edit `.env` with your actual values:

```bash
GITHUB_TOKEN=your_github_token          # Optional, for API enrichment
LLM_API_KEY=your_llm_api_key           # Required for LLM summarization
SMTP_USERNAME=your-email@example.com   # Your SMTP username
SMTP_PASSWORD=your-app-password        # Your SMTP password
```

**Note**: For Gmail, use an [App Password](https://support.google.com/accounts/answer/185833) instead of your regular password.

## Usage

### Default Mode (Run Once)

Execute the pipeline once and exit (this is the default behavior):

```bash
python -m src.scheduler
```

### Scheduler Mode

Run continuously with scheduled execution using APScheduler:

```bash
python -m src.scheduler --scheduler
```

### Send Latest Report

Generate and email a report from recent database entries:

```bash
python -m src.scheduler --send-email
```

### Command Line Arguments

- `--scheduler`: Run in scheduler mode (continuous execution with APScheduler)
- `--send-email`: Send the latest report via email
- `--email-file`: Path to a specific HTML report file to send (use with `--send-email`)
- `--config`: Path to configuration file (default: `config.yaml`)

## Automation with Crontab

### Setting Up Cron Job

To run the tracker automatically at scheduled times, use crontab:

```bash
# Edit crontab
crontab -e
```

### Crontab Examples

```bash
# Run daily at 9:00 AM
0 9 * * * cd /path/to/gh-trending-tracker && /path/to/venv/bin/python -m src.scheduler

# Run daily at 9:00 AM with output logged
0 9 * * * cd /path/to/gh-trending-tracker && /path/to/venv/bin/python -m src.scheduler >> logs/cron.log 2>&1

# Run every 6 hours
0 */6 * * * cd /path/to/gh-trending-tracker && /path/to/venv/bin/python -m src.scheduler

# Run weekly on Monday at 9:00 AM
0 9 * * 1 cd /path/to/gh-trending-tracker && /path/to/venv/bin/python -m src.scheduler
```

### Crontab Format

```
* * * * * command
│ │ │ │ │
│ │ │ │ └─── Day of week (0-7, Sunday = 0 or 7)
│ │ │ └───── Month (1-12)
│ │ └─────── Day of month (1-31)
│ └───────── Hour (0-23)
└─────────── Minute (0-59)
```

### Tips

1. **Always use absolute paths** in crontab
2. **Activate virtual environment** before running Python
3. **Log output** for debugging: `>> logs/cron.log 2>&1`
4. **Test manually first**: Run the command manually before adding to crontab
5. **Check cron logs**: `grep CRON /var/log/syslog` (on Ubuntu/Debian)

### Example: Complete Setup

```bash
# 1. Navigate to project directory
cd /path/to/gh-trending-tracker

# 2. Ensure virtual environment exists
source venv/bin/activate

# 3. Test run once
python -m src.scheduler

# 4. Edit crontab
crontab -e

# 5. Add this line (adjust paths as needed):
0 9 * * * cd /path/to/gh-trending-tracker && /path/to/gh-trending-tracker/venv/bin/python -m src.scheduler >> /path/to/gh-trending-tracker/logs/cron.log 2>&1

# 6. Verify crontab
crontab -l
```

## Project Structure

```
gh-trending-tracker/
├── src/
│   ├── __init__.py
│   ├── config.py           # Configuration management with Pydantic
│   ├── emailer.py          # Email sending with HTML templates
│   ├── fetcher.py          # GitHub API client for enrichment
│   ├── filter.py           # Repository filtering and persistence (SQLite)
│   ├── llm.py             # LLM integration (OpenAI/Anthropic-compatible)
│   ├── logger_config.py    # Centralized logging configuration
│   ├── main.py            # Module exports
│   ├── models.py          # Pydantic data models
│   ├── scheduler.py       # Main application and scheduler
│   └── trending_scraper.py # Web scraper for GitHub trending page
├── tests/
│   ├── test_core.py       # Core functionality tests
│   └── test_trending_scraper.py  # Scraper tests
├── data/                  # SQLite database storage
│   └── .gitkeep
├── logs/                  # Log files
│   └── .gitkeep
├── venv/                  # Python virtual environment
├── config.yaml            # Configuration file
├── requirements.txt       # Python dependencies
├── README.md             # This file
└── CLAUDE.md             # Project instructions for Claude Code
```

## How It Works

1. **Scraping**: The scraper fetches GitHub trending page and extracts repository information
   - Basic info: name, description, language, stars, forks
   - Today's star count from trending page

2. **Enrichment** (optional): If GitHub token is provided, use API to get additional details
   - Created/updated/pushed dates
   - Open issues count
   - Owner avatar URL
   - Uses concurrent requests for better performance

3. **Filtering**: Compare with database to identify new repositories
   - Repositories not seen in the last X days are considered "new"
   - Persists all seen repositories to SQLite database

4. **Summarization**: Use LLM to generate concise summaries for new repositories
   - Supports OpenAI, Anthropic, and compatible APIs
   - Customizable prompt template in config.yaml

5. **Email Report**: Send HTML email report with repository summaries
   - Simplified HTML to avoid spam filters
   - Includes repository cards with key information

## Logs

Logs are stored in the `logs/` directory with rotation:
- File format: `gh_trending_YYYYMMDD.log`
- Max size: 10MB per file
- Backup count: 5 files
- Console output also enabled

## Troubleshooting

### Email not sending
- Check SMTP credentials and settings
- For Gmail, use App Password instead of regular password
- Check if port 465 (SSL) or 587 (TLS) is correct for your SMTP provider
- Verify firewall settings allow outbound SMTP connections

### Scraping fails
- Check internet connection
- GitHub might be blocking requests (rate limiting or IP blocking)
- Check logs for error details
- Consider adding delays or using a GitHub token for API fallback

### LLM API errors
- Verify API key is correct
- Check if base_url is accessible (for custom endpoints)
- Ensure model name is correct for your provider
- Check API quota and rate limits

## License

MIT
